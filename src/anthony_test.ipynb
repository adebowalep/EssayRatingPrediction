{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librairies\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import dask.dataframe as dd\n",
    "import time\n",
    "\n",
    "from features import (count_awl_words, count_complex_words, count_sentences, \n",
    "                      count_syllables, count_words, count_awl_words, \n",
    "                      tokenize_essay, lemmatize_essay, remove_stop_words,\n",
    "                      remove_punctuation, remove_special_words, count_characters,\n",
    "                      count_dale_chall_difficult_words, count_unique_lemme, get_pos_tags,\n",
    "                      count_incorrect_words, get_incorrect_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.options.display.max_rows = 60\n",
    "# pd.options.display.max_seq_items = 100\n",
    "\n",
    "# # pd.reset_option(\"display.max_rows\")\n",
    "# # pd.reset_option(\"display.max_seq_items\")\n",
    "\n",
    "# pd.options.display.max_colwidth = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/training_set_rel3.tsv\", sep=\"\\t\", encoding=\"ISO-8859-1\")\n",
    "df_train = df_train.dropna(axis=1)\n",
    "df_test = df_train#.iloc[:5]\n",
    "df_test = df_test.drop(columns=[\"rater1_domain1\", \"rater2_domain1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1/13\n",
      "step 1 completed in  0.19565224647521973  seconds\n",
      "step 2/13\n",
      "step 2 completed in  0.8180291652679443  seconds\n",
      "step 3/13\n",
      "step 3 completed in  1.3315224647521973  seconds\n",
      "step 4/13\n",
      "step 4 completed in  0.722409725189209  seconds\n",
      "step 5/13\n",
      "step 5 completed in  1.0251719951629639  seconds\n",
      "step 6/13\n",
      "step 6 completed in  1.0667128562927246  seconds\n",
      "step 7/13\n",
      "step 7 completed in  71.39221620559692  seconds\n",
      "step 8/13\n",
      "step 8 completed in  64.4795835018158  seconds\n",
      "step 9/13\n",
      "step 9 completed in  2.0892388820648193  seconds\n",
      "step 10/13\n",
      "step 10 completed in  2.2550771236419678  seconds\n",
      "step 11/13\n",
      "step 11 completed in  2.144925832748413  seconds\n",
      "step 12/13\n"
     ]
    }
   ],
   "source": [
    "total_steps = 15\n",
    "\n",
    "pipeline_start = time.time()\n",
    "\n",
    "start = time.time()\n",
    "print(f\"step 1/{total_steps}\")\n",
    "\n",
    "ddf = dd.from_pandas(df_test, npartitions=32)\n",
    "df_test[\"essay\"] = ddf[\"essay\"].apply(remove_special_words)\n",
    "\n",
    "end = time.time()\n",
    "print(\"step 1 completed in \", end - start, \" seconds\")\n",
    "\n",
    "start = time.time()\n",
    "print(f\"step 2/{total_steps}\")\n",
    "\n",
    "ddf = dd.from_pandas(df_test, npartitions=32)\n",
    "df_test[\"essay\"] = ddf[\"essay\"].apply(remove_punctuation)\n",
    "\n",
    "end = time.time()\n",
    "print(\"step 2 completed in \", end - start, \" seconds\")\n",
    "\n",
    "start = time.time()\n",
    "print(f\"step 3/{total_steps}\")\n",
    "\n",
    "ddf = dd.from_pandas(df_test, npartitions=32)\n",
    "df_test[\"essay_tokens\"] = ddf[\"essay\"].apply(tokenize_essay)\n",
    "\n",
    "end = time.time()\n",
    "print(\"step 3 completed in \", end - start, \" seconds\")\n",
    "\n",
    "start = time.time()\n",
    "print(f\"step 4/{total_steps}\")\n",
    "\n",
    "ddf = dd.from_pandas(df_test, npartitions=32)\n",
    "df_test[\"count_words\"] = ddf[\"essay_tokens\"].apply(len)\n",
    "\n",
    "end = time.time()\n",
    "print(\"step 4 completed in \", end - start, \" seconds\")\n",
    "\n",
    "start = time.time()\n",
    "print(f\"step 5/{total_steps}\")\n",
    "\n",
    "ddf = dd.from_pandas(df_test, npartitions=32)\n",
    "df_test[\"count_awl_words\"] = ddf[\"essay_tokens\"].apply(count_awl_words)\n",
    "\n",
    "end = time.time()\n",
    "print(\"step 5 completed in \", end - start, \" seconds\")\n",
    "\n",
    "start = time.time()\n",
    "print(f\"step 6/{total_steps}\")\n",
    "\n",
    "ddf = dd.from_pandas(df_test, npartitions=32)\n",
    "df_test[\"essay_tokens_wo_stopwords\"] = ddf[\"essay_tokens\"].apply(remove_stop_words)\n",
    "\n",
    "end = time.time()\n",
    "print(\"step 6 completed in \", end - start, \" seconds\")\n",
    "\n",
    "start = time.time()\n",
    "print(f\"step 7/{total_steps}\")\n",
    "\n",
    "ddf = dd.from_pandas(df_test, npartitions=32)\n",
    "df_test[\"lemmatized_essay\"] = ddf[\"essay\"].apply(lemmatize_essay)\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print(\"step 7 completed in \", end - start, \" seconds\")\n",
    "\n",
    "start = time.time()\n",
    "print(f\"step 8/{total_steps}\")\n",
    "\n",
    "ddf = dd.from_pandas(df_test, npartitions=32)\n",
    "df_test[\"count_complex_words\"] = ddf[\"lemmatized_essay\"].apply(count_complex_words)\n",
    "\n",
    "end = time.time()\n",
    "print(\"step 8 completed in \", end - start, \" seconds\")\n",
    "\n",
    "start = time.time()\n",
    "print(f\"step 9/{total_steps}\")\n",
    "\n",
    "ddf = dd.from_pandas(df_test, npartitions=32)\n",
    "df_test[\"count_characters\"] = ddf[\"essay\"].apply(count_characters)\n",
    "\n",
    "end = time.time()\n",
    "print(\"step 9 completed in \", end - start, \" seconds\")\n",
    "\n",
    "start = time.time()\n",
    "print(f\"step 10/{total_steps}\")\n",
    "\n",
    "ddf = dd.from_pandas(df_test, npartitions=32)\n",
    "df_test[\"dale_chall_words\"] = ddf[\"essay_tokens\"].apply(count_dale_chall_difficult_words)\n",
    "\n",
    "end = time.time()\n",
    "print(\"step 10 completed in \", end - start, \" seconds\")\n",
    "\n",
    "start = time.time()\n",
    "print(f\"step 11/{total_steps}\")\n",
    "\n",
    "ddf = dd.from_pandas(df_test, npartitions=32)\n",
    "df_test[\"count_unique_lemme\"] = ddf[\"essay_tokens\"].apply(count_unique_lemme)\n",
    "\n",
    "end = time.time()\n",
    "print(\"step 11 completed in \", end - start, \" seconds\")\n",
    "\n",
    "start = time.time()\n",
    "df = pd.DataFrame()\n",
    "print(f\"step 12/{total_steps}\")\n",
    "ddf = dd.from_pandas(df_test, npartitions=32)\n",
    "df = ddf[\"essay_tokens\"].apply(get_pos_tags, meta=(pd.Series(dtype=\"object\")))\n",
    "df = pd.json_normalize(df)\n",
    "df_test = df_test.join(df, how=\"left\")\n",
    "end = time.time()\n",
    "print(\"step 12 completed in \", end - start, \" seconds\")\n",
    "\n",
    "start = time.time()\n",
    "print(f\"step 13/{total_steps}\")\n",
    "\n",
    "ddf = dd.from_pandas(df_test, npartitions=32)\n",
    "df_test[\"count_incorrect_words\"] = df_test[\"essay_tokens\"].apply(count_incorrect_words)\n",
    "end = time.time()\n",
    "print(\"step 13 completed in \", end - start, \" seconds\")\n",
    "\n",
    "start = time.time()\n",
    "print(f\"step 14/{total_steps}\")\n",
    "\n",
    "ddf = dd.from_pandas(df_test, npartitions=32)\n",
    "df_test[\"count_sentences\"] = df_test[\"essay\"].apply(count_sentences)\n",
    "end = time.time()\n",
    "print(\"step 14 completed in \", end - start, \" seconds\")\n",
    "\n",
    "start = time.time()\n",
    "print(f\"step 15/{total_steps}\")\n",
    "\n",
    "ddf = dd.from_pandas(df_test, npartitions=32)\n",
    "df_test[\"count_syllables\"] = df_test[\"essay_tokens\"].apply(count_syllables)\n",
    "end = time.time()\n",
    "print(\"step 15 completed in \", end - start, \" seconds\")\n",
    "\n",
    "pipeline_end = time.time()\n",
    "print(f\"execution of pipeline took {pipeline_end - pipeline_start} seconds\")\n",
    "\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jsoned = get_pos_tags(df_test[\"essay_tokens\"][0])\n",
    "\n",
    "# df = pd.json_normalize(jsoned)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df_test[\"essay_tokens\"].apply(get_pos_tags)\n",
    "# df = pd.json_normalize(df)\n",
    "# df\n",
    "\n",
    "# df_test = df_test.join(df)\n",
    "# df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test[\"count_incorrect_words\"] = df_test[\"essay_tokens\"].apply(count_incorrect_words)\n",
    "# df_test[\"get_incorrect_words\"] = df_test[\"essay_tokens\"].apply(get_incorrect_words)\n",
    "\n",
    "# df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>count_words</th>\n",
       "      <th>count_awl_words</th>\n",
       "      <th>count_complex_words</th>\n",
       "      <th>count_characters</th>\n",
       "      <th>dale_chall_words</th>\n",
       "      <th>count_unique_lemme</th>\n",
       "      <th>CC</th>\n",
       "      <th>CD</th>\n",
       "      <th>DT</th>\n",
       "      <th>...</th>\n",
       "      <th>VBD</th>\n",
       "      <th>VBG</th>\n",
       "      <th>VBN</th>\n",
       "      <th>VBP</th>\n",
       "      <th>VBZ</th>\n",
       "      <th>WDT</th>\n",
       "      <th>WP</th>\n",
       "      <th>WP$</th>\n",
       "      <th>WRB</th>\n",
       "      <th>count_incorrect_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>340</td>\n",
       "      <td>35</td>\n",
       "      <td>260</td>\n",
       "      <td>1442</td>\n",
       "      <td>73</td>\n",
       "      <td>162</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>409</td>\n",
       "      <td>47</td>\n",
       "      <td>317</td>\n",
       "      <td>1765</td>\n",
       "      <td>107</td>\n",
       "      <td>186</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>272</td>\n",
       "      <td>49</td>\n",
       "      <td>212</td>\n",
       "      <td>1185</td>\n",
       "      <td>71</td>\n",
       "      <td>142</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>484</td>\n",
       "      <td>85</td>\n",
       "      <td>393</td>\n",
       "      <td>2275</td>\n",
       "      <td>144</td>\n",
       "      <td>226</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>462</td>\n",
       "      <td>48</td>\n",
       "      <td>355</td>\n",
       "      <td>2023</td>\n",
       "      <td>88</td>\n",
       "      <td>196</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>54</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12971</th>\n",
       "      <td>35</td>\n",
       "      <td>792</td>\n",
       "      <td>44</td>\n",
       "      <td>594</td>\n",
       "      <td>3118</td>\n",
       "      <td>138</td>\n",
       "      <td>306</td>\n",
       "      <td>54</td>\n",
       "      <td>11</td>\n",
       "      <td>61</td>\n",
       "      <td>...</td>\n",
       "      <td>46</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12972</th>\n",
       "      <td>32</td>\n",
       "      <td>514</td>\n",
       "      <td>25</td>\n",
       "      <td>385</td>\n",
       "      <td>1971</td>\n",
       "      <td>93</td>\n",
       "      <td>203</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12973</th>\n",
       "      <td>40</td>\n",
       "      <td>761</td>\n",
       "      <td>66</td>\n",
       "      <td>583</td>\n",
       "      <td>3235</td>\n",
       "      <td>167</td>\n",
       "      <td>341</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>86</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12974</th>\n",
       "      <td>40</td>\n",
       "      <td>543</td>\n",
       "      <td>38</td>\n",
       "      <td>399</td>\n",
       "      <td>2181</td>\n",
       "      <td>141</td>\n",
       "      <td>234</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12975</th>\n",
       "      <td>40</td>\n",
       "      <td>460</td>\n",
       "      <td>38</td>\n",
       "      <td>331</td>\n",
       "      <td>1899</td>\n",
       "      <td>116</td>\n",
       "      <td>220</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12976 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       domain1_score  count_words  count_awl_words  count_complex_words  \\\n",
       "0                  8          340               35                  260   \n",
       "1                  9          409               47                  317   \n",
       "2                  7          272               49                  212   \n",
       "3                 10          484               85                  393   \n",
       "4                  8          462               48                  355   \n",
       "...              ...          ...              ...                  ...   \n",
       "12971             35          792               44                  594   \n",
       "12972             32          514               25                  385   \n",
       "12973             40          761               66                  583   \n",
       "12974             40          543               38                  399   \n",
       "12975             40          460               38                  331   \n",
       "\n",
       "       count_characters  dale_chall_words  count_unique_lemme  CC  CD  DT  \\\n",
       "0                  1442                73                 162  14   0  20   \n",
       "1                  1765               107                 186  18   5  34   \n",
       "2                  1185                71                 142  16   2  27   \n",
       "3                  2275               144                 226  17   0  45   \n",
       "4                  2023                88                 196  15   5  54   \n",
       "...                 ...               ...                 ...  ..  ..  ..   \n",
       "12971              3118               138                 306  54  11  61   \n",
       "12972              1971                93                 203  26   4  44   \n",
       "12973              3235               167                 341  35   5  86   \n",
       "12974              2181               141                 234  22   4  45   \n",
       "12975              1899               116                 220  12   1  37   \n",
       "\n",
       "       ...  VBD  VBG  VBN  VBP  VBZ  WDT  WP  WP$  WRB  count_incorrect_words  \n",
       "0      ...    2   15    6   17   10    0   1    0    4                     11  \n",
       "1      ...    5   20    6   21    6    3   0    0    9                     13  \n",
       "2      ...    0    9    0   25    5    0   5    0    3                      1  \n",
       "3      ...   17    5    9   21   11    1   3    0    4                     21  \n",
       "4      ...    2    6    2   26   16    3   1    0    5                     11  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ..  ...  ...                    ...  \n",
       "12971  ...   46    8   11   34   19    3   4    0    8                      1  \n",
       "12972  ...   42    9    5   19    6    2   0    0    3                      9  \n",
       "12973  ...   69   24   26    9   12    9   4    0    4                     12  \n",
       "12974  ...   44   13   15    9    9    1   6    0    7                      2  \n",
       "12975  ...   15   10   10   31   17    5   2    0    5                      1  \n",
       "\n",
       "[12976 rows x 44 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_test.drop(columns=[\"essay\", \"essay_id\", \"essay_set\", \"essay_tokens\", \"essay_tokens_wo_stopwords\", \"lemmatized_essay\"])\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['domain1_score', 'count_words', 'count_awl_words',\n",
       "       'count_complex_words', 'count_characters', 'dale_chall_words',\n",
       "       'count_unique_lemme', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR',\n",
       "       'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP',\n",
       "       'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG',\n",
       "       'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB',\n",
       "       'count_incorrect_words'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df_test,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.loc[:, ['count_words', 'count_awl_words',\n",
    "       'count_complex_words', 'count_characters', 'dale_chall_words',\n",
    "       'count_unique_lemme', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR',\n",
    "       'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP',\n",
    "       'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG',\n",
    "       'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB',\n",
    "       'count_incorrect_words']].values\n",
    "Y_train = df_train.domain1_score.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.loc[:, ['count_words', 'count_awl_words',\n",
    "       'count_complex_words', 'count_characters', 'dale_chall_words',\n",
    "       'count_unique_lemme', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR',\n",
    "       'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP',\n",
    "       'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG',\n",
    "       'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB',\n",
    "       'count_incorrect_words']].values\n",
    "Y_test = df_test.domain1_score.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7380748541915985\n"
     ]
    }
   ],
   "source": [
    "regr = LinearRegression()\n",
    "regr.fit(X_train, Y_train)\n",
    "print(regr.score(X_test, Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_erp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
